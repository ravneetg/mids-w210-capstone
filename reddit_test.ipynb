{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "con_uri = \"mongodb://w210_db_user:q1w2e3r4$@198.11.212.212:27017/w210_db\"\n",
    "cli = MongoClient(con_uri)\n",
    "db = cli.w210_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5b1c8f2148d6215496c4d2c7,https://www.reddit.com/user/SmarterCrypto/\n",
      "5b1c8f2148d6215496c4d2c7,SmarterCrypto\n",
      "5b1c8f2148d6215496c4d2c8,https://www.reddit.com/user/cellblocks/\n",
      "5b1c8f2148d6215496c4d2c8,cellblocks\n",
      "5b1c8f2148d6215496c4d2ca,https://www.reddit.com/r/Sentinel_Protocol/\n",
      "5b1c8f2148d6215496c4d2ca,Sentinel_Protocol\n",
      "5b1c8f2248d6215496c4d2cd,https://www.reddit.com/user/LevelNetwork/\n",
      "5b1c8f2248d6215496c4d2cd,LevelNetwork\n",
      "5b1c8f2248d6215496c4d2d0,https://www.reddit.com/user/MultiversumBC/\n",
      "5b1c8f2248d6215496c4d2d0,MultiversumBC\n",
      "5b1c8f2248d6215496c4d2d3,https://www.reddit.com/user/Winances/comments/8b6ev1/winances_brand_new_exchange/\n",
      "5b1c8f2248d6215496c4d2d3,winances_brand_new_exchange\n",
      "5b1c8f2248d6215496c4d2d4,https://www.reddit.com/user/ACU_Russ\n",
      "5b1c8f2248d6215496c4d2d4,ACU_Russ\n",
      "5b1c8f2248d6215496c4d2d5,https://www.reddit.com/r/CarVDB/\n",
      "5b1c8f2248d6215496c4d2d5,CarVDB\n",
      "5b1c8f2348d6215496c4d2d8,https://www.reddit.com/user/RusGas/\n",
      "5b1c8f2348d6215496c4d2d8,RusGas\n",
      "5b1c8f2348d6215496c4d2db,https://www.reddit.com/r/Eventum/\n",
      "5b1c8f2348d6215496c4d2db,Eventum\n",
      "5b1c8f2348d6215496c4d2dc,https://www.reddit.com/user/Countinghouse_Fund\n",
      "5b1c8f2348d6215496c4d2dc,Countinghouse_Fund\n",
      "5b1c8f2348d6215496c4d2e0,https://www.reddit.com/user/AX1mining/\n",
      "5b1c8f2348d6215496c4d2e0,AX1mining\n",
      "5b1c8f2448d6215496c4d2e2,https://www.reddit.com/r/Shop_/\n",
      "5b1c8f2448d6215496c4d2e2,Shop_\n",
      "5b1c8f2448d6215496c4d2e8,https://www.reddit.com/r/synapseai/\n",
      "5b1c8f2448d6215496c4d2e8,synapseai\n",
      "5b1c8f2448d6215496c4d2ea,https://www.reddit.com/user/blockshipping\n",
      "5b1c8f2448d6215496c4d2ea,blockshipping\n",
      "5b1c8f2548d6215496c4d2ec,https://reddit.com/r/parsecfrontiers\n",
      "5b1c8f2548d6215496c4d2ec,parsecfrontiers\n",
      "5b1c8f2548d6215496c4d2f1,https://reddit.com/u/bestmetagg\n",
      "5b1c8f2548d6215496c4d2f1,bestmetagg\n",
      "5b1c8f2548d6215496c4d2f2,https://www.reddit.com/user/PORN_coin/\n",
      "5b1c8f2548d6215496c4d2f2,PORN_coin\n",
      "5b1c8f2548d6215496c4d2f3,https://www.reddit.com/r/Localcoinswap/\n",
      "5b1c8f2548d6215496c4d2f3,Localcoinswap\n"
     ]
    }
   ],
   "source": [
    "coll = db[\"icotracker_ico\"]\n",
    "cursor = coll.find({}) #.sort('num_icos',pymongo.DESCENDING)\n",
    "# print \"\"\n",
    "i=0\n",
    "j=0\n",
    "for x in cursor:\n",
    "#     print \"{}\".format(x['social']['Telegram'])\n",
    "    _id = x['_id']\n",
    "    if 'Reddit' in x['social']:\n",
    "        print \"{},{}\".format(_id, x['social']['Reddit'])\n",
    "        if x['social']['Reddit'][-1]==\"/\":\n",
    "            print \"{},{}\".format(_id, x['social']['Reddit'].split(\"/\")[-2])\n",
    "            in_token_name = x['social']['Reddit'].split(\"/\")[-2]\n",
    "#             load_count = call_reddit_and_loadDB(in_token_name, str(_id))\n",
    "        else:\n",
    "            print \"{},{}\".format(_id, x['social']['Reddit'].split(\"/\")[-1])\n",
    "            in_token_name = x['social']['Reddit'].split(\"/\")[-1]\n",
    "#             load_count = call_reddit_and_loadDB(in_token_name, str(_id))\n",
    "        j+=1\n",
    "#         break\n",
    "    i+=1\n",
    "    \n",
    "    if i>50:\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ico_sr_url = \"https://www.reddit.com/r/Eventum/\"\n",
    "ico_sr_url_post = \"https://www.reddit.com/r/datascience/comments/8osl88/data_science_interviews/\"\n",
    "# \"https://www.reddit.com/r/Eventum/comments/854agw/eventum_everything_you_need_to_know/\"\n",
    "sr_about = \"about/contributors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(ico_sr_url_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8osl88\n",
      "8osl88\n"
     ]
    }
   ],
   "source": [
    "reviewurl = urlparse(ico_sr_url_post)\n",
    "submission_id = reviewurl.path.split('/')[4]\n",
    "print submission_id\n",
    "submission = reddit.submission(id=submission_id)\n",
    "print submission\n",
    "# sr_post = submission.comments(submission_id='854agw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3\n"
     ]
    }
   ],
   "source": [
    "print i, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit using about.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from time import sleep\n",
    "from webscraping import download, xpath\n",
    "import json\n",
    "D = download.Download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.reddit.com/r/datascience/comments/8osl88/data_science_interviews/about.json \n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.reddit.com/r/datascience/comments/8osl88/data_science_interviews/about.json\"\n",
    "json_data = D.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_sr = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reddit_dict = dict()\n",
    "reddit_dict['num_comments'] = json_sr[0]['data']['children'][0]['data']['num_comments']\n",
    "reddit_dict['score'] = json_sr[0]['data']['children'][0]['data']['score']\n",
    "reddit_dict['subreddit_subscribers'] = json_sr[0]['data']['children'][0]['data']['subreddit_subscribers']\n",
    "reddit_dict['ups'] = json_sr[0]['data']['children'][0]['data']['ups']\n",
    "reddit_dict['upvote_ratio'] = json_sr[0]['data']['children'][0]['data']['upvote_ratio']\n",
    "reddit_dict['author'] = json_sr[0]['data']['children'][0]['data']['author']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': u'vorat',\n",
       " 'num_comments': 23,\n",
       " 'score': 12,\n",
       " 'subreddit_subscribers': 65686,\n",
       " 'ups': 12,\n",
       " 'upvote_ratio': 0.88}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://www.reddit.com/r/Eventum/about.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_sr = json.loads(D.get(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_sr[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reddit_dict = dict()\n",
    "reddit_dict['subscribers'] = json_sr['data']['subscribers']\n",
    "reddit_dict['active_user_count'] = json_sr['data']['active_user_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_user_count': 6, 'subscribers': 4905}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.reddit.com/user/AX1mining/about.json \n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.reddit.com/user/AX1mining/about.json\"\n",
    "json_sr = json.loads(D.get(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit_dict = dict()\n",
    "reddit_dict['num_comments'] = json_sr[0]['data']['children'][0]['data']['num_comments']\n",
    "reddit_dict['score'] = json_sr[0]['data']['children'][0]['data']['score']\n",
    "reddit_dict['subreddit_subscribers'] = json_sr[0]['data']['children'][0]['data']['subreddit_subscribers']\n",
    "reddit_dict['ups'] = json_sr[0]['data']['children'][0]['data']['ups']\n",
    "reddit_dict['upvote_ratio'] = json_sr[0]['data']['children'][0]['data']['upvote_ratio']\n",
    "reddit_dict['author'] = json_sr[0]['data']['children'][0]['data']['author']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get url for each post in a subreddit and load to mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bson.objectid import ObjectId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from pymongo import MongoClient\n",
    "import pymongo\n",
    "con_uri = \"mongodb://w210_db_user:q1w2e3r4$@198.11.212.212:27017/w210_db\"\n",
    "cli = MongoClient(con_uri)\n",
    "db = cli.w210_db\n",
    "coll = db[\"ico_subreddit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_db(in_dict):\n",
    "    coll = db[\"ico_subreddit\"]\n",
    "#     coll.insert_one(in_dict)\n",
    "    flag = coll.find({\"url\": in_dict['url']}).count()\n",
    "#     print flag\n",
    "    if flag == 0:\n",
    "        coll.insert_one(in_dict)\n",
    "        return \"Sucess\"\n",
    "    else:\n",
    "        return \"Duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call_reddit_and_loadDB(in_token_name, in_token_fkey):\n",
    "#     tokenw = 'Eventum'\n",
    "    subreddit = reddit.subreddit(in_token_name)\n",
    "\n",
    "    # url = \"https://www.reddit.com/r/Eventum/about.json\"\n",
    "    # json_sr = json.loads(D.get(url))\n",
    "    # reddit_dict['subscribers'] = json_sr['data']['subscribers']\n",
    "    # reddit_dict['active_user_count'] = json_sr['data']['active_user_count']\n",
    "\n",
    "    # print(subreddit.display_name)  # Output: redditdev\n",
    "    i=0\n",
    "    try:\n",
    "#     if subreddit.hot(limit=1000):\n",
    "        sr_dict= None\n",
    "        for submission in subreddit.hot(limit=1000):\n",
    "            sr_dict = dict()\n",
    "            sr_dict['score'] = submission.score  # Output: the submission's score\n",
    "            sr_dict['id'] = submission.id     # Output: the submission's ID\n",
    "            sr_dict['url'] = submission.url    # Output: the URL the submission points to\n",
    "            if submission.author:\n",
    "                sr_dict['author'] = submission.author.name    # or the submission's URL if it's a self post\n",
    "            else:\n",
    "                sr_dict['author'] = None\n",
    "            sr_dict['num_comments'] = submission.num_comments\n",
    "            sr_dict['name_sr'] = subreddit.display_name\n",
    "            sr_dict['name'] = in_token_name\n",
    "            sr_dict['ico_fkey'] = in_token_fkey\n",
    "            sr_dict['status'] = 'subreddit_success'\n",
    "            db_load_status = load_db(sr_dict)\n",
    "    #         print db_load_status\n",
    "            i+=1\n",
    "    #             if i>5:\n",
    "    #                 break\n",
    "        if sr_dict:\n",
    "            print i, \"total loaded for subreddit\", sr_dict['name']\n",
    "        return i\n",
    "#     except Redirect:\n",
    "    except Exception as e:\n",
    "        return \"reddit_exception\"\n",
    "#         sr_dict = dict()\n",
    "#         sr_dict['name'] = in_token_name\n",
    "#         sr_dict['ico_fkey'] = in_token_fkey\n",
    "#         sr_dict['status'] = 'failed - redirect'\n",
    "#         db_load_status = load_db(sr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call_sleep():\n",
    "    ts = random.uniform(1.0,10.0)\n",
    "    print \"---- sleep time (in secs) =\", ts\n",
    "    sleep(ts)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coll = db[\"icotracker_ico\"]\n",
    "cursor = coll.find({\"status\": \"processed\"}) #.sort('num_icos',pymongo.DESCENDING)\n",
    "i=0\n",
    "j=0\n",
    "for x in cursor:\n",
    "    _id = x['_id']\n",
    "    print _id\n",
    "    if 'Reddit' in x['social']:\n",
    "        reddit_url = x['social']['Reddit']\n",
    "        if '/user/' in reddit_url or 'reddit.com/u' in reddit_url:\n",
    "            print \"Not a subreddit - {},{}\".format(_id, reddit_url)\n",
    "            if x['social']['Reddit'][-1]==\"/\":\n",
    "                in_token_name = reddit_url.split(\"/\")[-2]\n",
    "            else:\n",
    "                in_token_name = reddit_url.split(\"/\")[-1]\n",
    "            sr_dict = dict()\n",
    "            sr_dict['ico_fkey'] = _id\n",
    "            sr_dict['status'] = 'failed_user_url'\n",
    "            sr_dict['name'] = in_token_name\n",
    "            sr_dict['url']= reddit_url\n",
    "            db_load_status = load_db(sr_dict)\n",
    "            db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":\"not_a_sr\"}}, upsert=False)\n",
    "        elif '/r/' in reddit_url:\n",
    "            print \"Subreddit {},{}\".format(_id, reddit_url)\n",
    "            if x['social']['Reddit'][-1]==\"/\":\n",
    "                in_token_name = reddit_url.split(\"/\")[-2]\n",
    "                print in_token_name\n",
    "                count_flag = db[\"ico_subreddit\"].find({\"name\":in_token_name}).count()\n",
    "                if count_flag==0:\n",
    "                    load_count = call_reddit_and_loadDB(in_token_name, str(_id))\n",
    "                    call_sleep()\n",
    "                    if type(load_count) is int:\n",
    "                        db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":\"loaded\"}}, upsert=False)\n",
    "                    else:\n",
    "                        db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":load_count}}, upsert=False)\n",
    "                else:\n",
    "                    print \"Already loaded -\", in_token_name\n",
    "                    db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":\"loaded\"}}, upsert=False)\n",
    "\n",
    "            else:\n",
    "                in_token_name = reddit_url.split(\"/\")[-1]\n",
    "                print in_token_name\n",
    "                count_flag = db[\"ico_subreddit\"].find({\"name\":in_token_name}).count()\n",
    "                if count_flag==0:\n",
    "                    load_count = call_reddit_and_loadDB(in_token_name, str(_id))\n",
    "                    call_sleep()\n",
    "                    if type(load_count) is int:\n",
    "                        db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":\"loaded\"}}, upsert=False)\n",
    "                    else:\n",
    "                        db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":load_count}}, upsert=False)\n",
    "                else:\n",
    "                    print \"Already loaded -\", in_token_name\n",
    "                    db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":\"loaded\"}}, upsert=False)\n",
    "            j+=1\n",
    "        else:\n",
    "            db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":\"bad_reddit_url\"}}, upsert=False)\n",
    "#             break\n",
    "        i+=1    \n",
    "    else:\n",
    "        db[\"icotracker_ico\"].update_one({'_id':ObjectId(_id)}, {\"$set\": {\"status\":\"no_reddit\"}}, upsert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# code for testing reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">I have been networking more lately, and I'm hoping that proves fruitful in facilitating through the interview processes. \n",
      "\n",
      "Big time.\n",
      "8 patrickSwayzeNU\n",
      "\tI just started at a company and I have yet to meet someone who doesn’t mention having a reference when we talk about how they got here. \n",
      "\t\t*** []\n",
      "\tSeriously.  I got my first job through my college's job board, and my second one via LinkedIn.  So I've never had a job where I just submitted a resume the normal way.\n",
      "\t\t*** [u'The second more than the first but those sound like pretty normal ways to get a job lol']\n",
      "==================\n",
      "We don't know you and haven't seen you interview, so it's really hard to give you advice.  I recommend asking someone you trust and who you know is professional to give you a mock interview.  Ask them to give you brutally honest feedback.  If you're in college, your career center should offer that as a service.  Some colleges even offer it as a service to alumni.\n",
      "13 coffeecoffeecoffeee\n",
      "\tDone this both ways, nothing really useful came out of it. I am not nervous in these cases, so I likely come across very different, too. \n",
      "\t\t*** []\n",
      "==================\n",
      "I was once told that I didn't get the job--even though I had the most experience, was (according to all the interviewers) the best fit, and was the most enthusiastic about the position--because I was already employed and they thought that one of the other candidates who, at the time, was unemployed would be \"more loyal.\"\n",
      "\n",
      "Job offers can happen or not happen for any reason.  Networks and being in the right place at the right time are likely to be the best ways to get a killer position. Good luck.\n",
      "6 MattDamonsTaco\n",
      "==================\n",
      "What city are you in? Curious about the level of competition you are facing. \n",
      "6 most_humblest_ever\n",
      "\tI'm in Ohio. I'm interviewing all over the country though and am open to relocation, as long as the cost of living isn't crazy.\n",
      "\t\t*** []\n",
      "==================\n",
      "I have had some similar experiences, although not to this extent. My sense is that culture fit becomes more important at the last step.\n",
      "3 kroenke_out\n",
      "\tMy sympathies for your lost vacation days.\n",
      "\t\t*** []\n",
      "==================\n",
      "What’s your experience?\n",
      "2 loxc\n",
      "\tGraduated 2013 with MS, did a couple semesters of a PhD in stats then got a job in industry as kind of a consultant doing a bunch of random advanced analytics and BI stuff for an assortment of industries.\n",
      "\t\t*** []\n",
      "==================\n",
      "Since you've made it to the final round a few times, I would think that you meet the educational/technical qualification plus you've cleared the technical rounds as well. Do you work by yourself or in teams? I am trying to get to whether your experience highlights you working in teams. This prolly goes in line with culture fit.\n",
      "2 fakehyperloop\n",
      "\tI'm the only data scientist in my office, so I do all of that stuff mostly alone. I work with others on the analytics team when i jump in on business intelligence projects, where I'm usually given the SQL problems people get stuck on. Also, a lot of my projects are collaborations between me and other teams/departments.\n",
      "\t\t*** [u\"Gotcha! You may already be highlighting the team work, but if not, maybe try to make sure that it doesn't get left out. \\n\\nGood luck! Hope you get the next gig you apply to.\"]\n",
      "==================\n",
      "I've posted this in this subreddit before: [How to survive your data science interview](https://ai.works-hub.com/learn/how-to-ace-survive-your-data-science-interview-05170?utm_source=reddit&utm_medium=link&utm_campaign=lukas).\n",
      "It was written by Brandon Rohrer a Data Scientist at Facebook and formally Microsoft. It's got some good detail of things to prepare for, just incase there's anything you're missing. \n",
      "2 HAL8990\n",
      "==================\n",
      "Sounds like your social skills are terrible enough they just don't want to hire you.\n",
      "\n",
      "Video a mock interview and post it :)\n",
      "1 Revolutionary_Door\n",
      "\tCollaboration and teamwork seems to always be my highest rated component of my reviews in my current role, but yeah, it definitely seems like I'm not coming across as likable in the interview setting. Tempting.. :)\n",
      "\t\t*** [u'Social skills in an interview are different from social skills in a team.\\n\\nIf you\\'re a dick but a fair dick that takes other people into account, is not petty/hard to work with etc. then being a dick is a tiny thing people are willing to overlook and they don\\'t mind.\\n\\nBut in an interview you\\'ll fail because you have the \"he\\'s a dick\" vibe.\\n\\nThis also works the other way around. The perfect guy in an interview can be impossible to work with.']\n",
      "==================\n",
      "We don't know you, we haven't interviewed you. Get some friends to. Ask them to be honest even if it means hurting your feelings. For your part you have to be good about taking potentially hurtful criticism. All Reddit can really do for you is look through your CV and at the kind of jobs you're applying for. \n",
      "1 odditycat\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "i,j=0,0\n",
    "for top_level_comment in submission.comments:\n",
    "    print top_level_comment.body\n",
    "    print top_level_comment.score, top_level_comment.author\n",
    "    for x in top_level_comment.replies:\n",
    "        print \"\\t\",x.body\n",
    "        print \"\\t\\t***\", [z.body for z in x.replies]\n",
    "        j += len([z.body for z in x.replies])\n",
    "#         for y in x.replies:\n",
    "#             print \"\\t\\t\",y.body\n",
    "#             j+=1\n",
    "    i+=1\n",
    "    print(\"==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parse() takes exactly 3 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-34e82d0d9dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: parse() takes exactly 3 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "for x in subreddit.parse():\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for x in subreddit.comments:\n",
    "#     print x\n",
    "#     i+=1\n",
    "print(subreddit.display_name)\n",
    "print(subreddit.title)\n",
    "print(subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewurl = urlparse(ico_sr_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='www.reddit.com', path='/r/Eventum/comments/854agw/eventum_everything_you_need_to_know/', params='', query='', fragment='')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eventum'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_name = reviewurl.path.split('/')[2]\n",
    "subreddit_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STR_FIELD',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_chunk',\n",
       " '_comments_by_id',\n",
       " '_fetch',\n",
       " '_fetched',\n",
       " '_flair',\n",
       " '_info_params',\n",
       " '_info_path',\n",
       " '_mod',\n",
       " '_reddit',\n",
       " '_reset_attributes',\n",
       " '_safely_add_arguments',\n",
       " '_url_parts',\n",
       " '_vote',\n",
       " 'clear_vote',\n",
       " 'comment_limit',\n",
       " 'comment_sort',\n",
       " 'comments',\n",
       " 'crosspost',\n",
       " 'delete',\n",
       " 'disable_inbox_replies',\n",
       " 'downvote',\n",
       " 'duplicates',\n",
       " 'edit',\n",
       " 'enable_inbox_replies',\n",
       " 'flair',\n",
       " 'fullname',\n",
       " 'gild',\n",
       " 'hide',\n",
       " 'id',\n",
       " 'id_from_url',\n",
       " 'mod',\n",
       " 'parse',\n",
       " 'reply',\n",
       " 'report',\n",
       " 'save',\n",
       " 'shortlink',\n",
       " 'unhide',\n",
       " 'unsave',\n",
       " 'upvote']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = reddit.submission(id=\"854agw\")\n",
    "dir(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post._info_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(ico_sr_url)\n",
    "\n",
    "print(subreddit.display_name)\n",
    "print(subreddit.title)\n",
    "print(subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='',\n",
    "                     client_secret='',\n",
    "                     password='',\n",
    "                     user_agent='testscript by /u/fakebot3',\n",
    "                     username='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction (by /u/USERNAME)',\n",
    "                     client_id=' ', client_secret=\" \",\n",
    "                     username=' ', password=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "funny_url = 'https://www.reddit.com/r/funny/comments/3g1jfi/buttons/'\n",
    "trx_url = \"https://www.reddit.com/r/Tronix/comments/8oh2lv/news_coinex_will_open_trading_and_deposit_of_trx/\"\n",
    "submission = reddit.submission(url=trx_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = reddit.submission(id='3g1jfi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's gonna moon so hard that I'm gonna find a urologist to permanently turn my pee gold \n",
      "----------------------------------------------------------------------------------------------------\n",
      "View in your timezone:  \n",
      "[at 3:00 June 6th, 2018 (UTC)][0]  \n",
      "[0]: https://timee.io/20180606T0300?tl=NEWS%3A%20CoinEx%20will%20open%20trading%20and%20deposit%20of%20TRX%20and%20launched%20TRX%2FBCH%20%26%20TRX%2FBTC%20trading%20pairs%20at%203%3A00%20June%206th%2C%202018%20(UTC).\n",
      "\n",
      "\n",
      "*****\n",
      "\n",
      "[^^delete*](/message/compose?to=timee_bot&subject=delete+request&message=%21delete+eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJlMDM4aGp5IiwiYWN0IjoiZGVsZXRlIiwib3AiOiJkaWRhbmciLCJpYXQiOjE1MjgxMTcyNzd9.KT8WH-KNpdm8oRPWWYWpJEIlz8ES5YMsMIOkL24-BgU)\n",
      "^^|\n",
      "[^^reprocess*](/message/compose?to=timee_bot&subject=reprocess+request&message=%21reprocess+eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJlMDM4aGp5IiwiYWN0IjoicmVwcm9jZXNzIiwib3AiOiJkaWRhbmciLCJwbm0iOiJ0M184b2gybHYiLCJpYXQiOjE1MjgxMTcyNzd9.ATi4PjZNtzDCneaWqfeRs1y_M8QfrHPBqCZOc54ukgc)\n",
      "^^|\n",
      "[^^ignore ^^me](/message/compose?to=timee_bot&subject=ignore+request&message=%21ignore+me)\n",
      "^^|\n",
      "[^^help](https://www.reddit.com/r/timee_bot/wiki/index)\n",
      "\n",
      "^^*OP ^^only\n",
      "----------------------------------------------------------------------------------------------------\n",
      "^The linked tweet was tweeted by [@justinsuntron](https://twitter.com/justinsuntron) on Jun 04, 2018 09:03:15 UTC (190 Retweets | 606 Favorites)\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "\\#TRON $TRX \\#TRX will be listed on [@coinexcom](https://twitter.com/coinexcom) , you can deposit \\#TRX and trade TRX/BCH, TRX/BTC at 11:00am, June 6, 2018 (GMT+8) 🔊 \n",
      "\n",
      "[Attached photo](https://pbs.twimg.com/media/De1ewbFU0AAMzHB.jpg:orig) | [imgur Mirror](https://i.imgur.com/erSD8Rr.jpg)\n",
      "\n",
      "-------------------------------------------------\n",
      "\n",
      "^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for top_level_comment in submission.comments:\n",
    "    print(top_level_comment.body)\n",
    "    print \"-\"*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print submission.num_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'NEWS: CoinEx will open trading and deposit of TRX and launched TRX/BCH & TRX/BTC trading pairs at 3:00 June 6th, 2018 (UTC).'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit(display_name='Tronix')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /home/blue/anaconda2/lib/python2.7/site-packages (5.4.0)\n",
      "Requirement already satisfied: prawcore<0.15,>=0.14.0 in /home/blue/anaconda2/lib/python2.7/site-packages (from praw) (0.14.0)\n",
      "Requirement already satisfied: update-checker>=0.16 in /home/blue/anaconda2/lib/python2.7/site-packages (from praw) (0.16)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /home/blue/anaconda2/lib/python2.7/site-packages (from prawcore<0.15,>=0.14.0->praw) (2.13.0)\n",
      "\u001b[31mpydot-ng 1.0.1.dev0 has requirement pyparsing>=2.0.1, but you'll have pyparsing 1.5.6 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.12 :: Anaconda custom (64-bit)\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from configparser import ConfigParser\n",
    "# from urllib.parse import urlparse\n",
    "import urlparse\n",
    "import praw\n",
    "from urlparse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blue/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "config = ConfigParser()  \n",
    "# config.read(os.path.join(os.path.expanduser('~'), 'reddit_api.ini'))\n",
    "config.read('/home/blue/ds/w210/mids-w210-capstone/reddit_api.ini')\n",
    "client_id = config.get('client', 'id')  \n",
    "client_secret = config.get('client', 'secret')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=client_id, client_secret=client_secret, user_agent='testscript by /u/fakebot3')\n",
    "#                      user_agent='linux:edu.berkeley.ischool.whiskey_mids:v0.1.0 (by /u/TonyUCBerkeleyMIDS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(reddit.read_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Review Classics #3: Macallan 12 (any bottle, will segregate results)\n",
      "Review: Ben Nevis 18 - Cadenhead's Rum Cask\n",
      "Bunnahabhain plans to release a 20yr cask strength finished in Palo cortado cask.\n",
      "Review #3/4 Aberlour 12 (R)and Benromach 10(L)\n",
      "Review #391 - Highland Park 21y 1979 (Adelphi Selection)\n",
      "Review #11-14: Several Glens\n",
      "Review: SMWS 73.84 (Aultmore) “Tug of war in a meadow”\n",
      "\"Tickling/numbing\" feeling in the nose\n",
      "Quarter Cask Question\n",
      "Kilchoman 4 2011 PX KWM Cask 446 & Kilchoman 5 2010 KWM Cask 440 [Review]\n"
     ]
    }
   ],
   "source": [
    "for submission in reddit.subreddit('scotch').hot(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'user', 'shane_il', '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badurl = 'https://www.reddit.com/user/shane_il/'\n",
    "\n",
    "parsed_badurl = urlparse(badurl)\n",
    "#parsed_badurl\n",
    "parsed_badurl.path.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='http', netloc='www.reddit.com', path='/r/bourbon/comments/1v2xl0/review_4_george_t_stagg_2011_release/', params='', query='', fragment='')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewurl = urlparse('http://www.reddit.com/r/bourbon/comments/1v2xl0/review_4_george_t_stagg_2011_release/')\n",
    "reviewurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='', netloc='', path='www.reddit.com/r/bourbon/comments/1v2xl0', params='', query='', fragment='')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlparse('www.reddit.com/r/bourbon/comments/1v2xl0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'r',\n",
       " 'bourbon',\n",
       " 'comments',\n",
       " '1v2xl0',\n",
       " 'review_4_george_t_stagg_2011_release',\n",
       " '']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewurl.path.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bourbon'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_name = reviewurl.path.split('/')[2]\n",
    "subreddit_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bourbon\n",
      "Bourbon - America's Spirit\n",
      "###### [r/Whisky](/r/Whisky)[r/WorldWhisky](/r/WorldWhisky)[r/Scotch](/r/scotch)[/r/Whiskyporn](/r/whiskyporn)[Whisky Network Guide](https://docs.google.com/document/d/186_ANEKW8yGvvLAcjKve6tvqqBIcMGUg9-mKU5KACZk/edit)\n",
      "\n",
      "### \n",
      "\n",
      "* **[The /r/Bourbon Rules & Guidelines](https://docs.google.com/document/d/14MJyu97Sot78qJ0Rme5x4gW2rizTMBMHWThtmG8X7ok)**\n",
      "\n",
      "\n",
      "\n",
      "# **Welcome to rBourbon**\n",
      "\n",
      "All Discussions and Reviews of **Bourbon, Rye**, and/or any **American Whiskey** are welcome and encouraged(yes, even Jack).  As well as any news articles or bourbon related internet things.  \n",
      "\n",
      "\n",
      "* **[OFFICIAL NETWORK  IRC CHATROOM](https://kiwiirc.com/client/irc.snoonet.org/#RedditWhiskyNetwork)**\n",
      "\n",
      "* **[NETWORK DISCORD SERVER](https://discord.gg/8k8Hnpj)**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# **Helpful Stuff**\n",
      "\n",
      "* **[Bourbon FAQ](https://docs.google.com/document/d/17CCQ-r4mpH9krhrDiXVSayYkqWAjYGOCLh3NShV1yO8/edit#heading=h.7yx2snahgko8)**\n",
      "\n",
      "* **[Beginner's and Intermediate Guide to Bourbon](https://docs.google.com/document/d/10zdeEAO3GVayZtt-XsTcoGIi2uP8xrE8BurIxeSNfBk/edit)**\n",
      "\n",
      "* [**Bourbon Gift Guide**](https://www.reddit.com/r/bourbon/comments/4tcswq/new_improved_rbourbon_gift_guide/)\n",
      "\n",
      "* [**Rye Whiskey Guide**](https://docs.google.com/document/d/1mrVZabQaulkxqL2qLif4HlWpMXF0bQ6hAmr8aQ_kRYA/edit#heading=h.lqvwwdjxkepg)\n",
      "\n",
      "* **[Kentucky Bourbon Trail Guide](https://docs.google.com/document/d/1hKcFqNtKBrqzFPKJVye-wz0mbLChj9haguY4l_iRgtI/edit?usp=sharing)**\n",
      "\n",
      "* **[Whiskey Acronyms](https://docs.google.com/document/d/1smJfhOgp-ObOZ0Va1a3QeWDqVxmFdqO-RnKZe5ap83c/edit?usp=sharing)**\n",
      "\n",
      "# **Review Stuff**\n",
      "\n",
      "* **[Whisky Review Archive](https://docs.google.com/spreadsheets/d/1X1HTxkI6SqsdpNSkSSivMzpxNT-oeTbjFFDdEkXD30o/edit#gid=695409533&fvid=484110565)**\n",
      "\n",
      "\n",
      "* **[Review Archive Mobile Search](http://whiskynetworkreviews.com/)**\n",
      "\n",
      "\n",
      "* **[Submission Form](https://docs.google.com/forms/d/13O0_erDx22pP2Gdkc6hYkOkgG3N5l718-jtrIok_9xE/viewform)**\n",
      "\n",
      "\n",
      "* **[Community Reviews](https://docs.google.com/document/d/1PNUikuLjMEarQpMklvfb0W3SVz2dfFMrkDKbKTECiK8/edit)**\n",
      "\n",
      "\n",
      "\n",
      "* **[Texacer's Guide to Tasting/Nosing/Reviewing](https://docs.google.com/document/d/1vawB2eCdPPfZxg0Qdw12CgrB-qCtxKX5_2due01tSqw/edit?hl=en_US)**\n",
      "\n",
      "\n",
      "# **AMAs**\n",
      "\n",
      "* **[Buffalo Trace](https://docs.google.com/document/d/1E-aC3EOkKNoMl56ZgC9wt_RgN8bxY3xm0z9aS3nQxq8/edit#)**\n",
      "\n",
      "* **[Lost Spirits](https://docs.google.com/document/d/1ODQGhT_82iv4Xu33BJ-wnO1OkM1O47d2hHxVf5UI8Eg/edit?usp=sharing)**\n",
      "\n",
      "* **[Four Roses](https://docs.google.com/document/d/1uXjdoVONi8NGC-cy2fc3uzyY9wC63AhrZEmGIJu_Vcg/edit)**\n",
      "\n",
      "* **[Wild Turkey](https://docs.google.com/document/d/1Q0n8gQJmv0MVzVMGgIwDDkHwT_kBIQucL9L5Dhrtia4/edit)**\n",
      "\n",
      "* **[Balcones](http://www.reddit.com/r/bourbon/comments/27h95f/i_am_winston_edwards_balcones_brand_ambassador_ama/)**\n",
      "\n",
      "* **[Smooth Ambler](https://www.reddit.com/r/bourbon/comments/2uzf0b/john_foster_ama_smooth_ambler/)**\n",
      "\n",
      "* **[High West](https://www.reddit.com/r/bourbon/comments/4560c1/i_am_david_perkins_founder_of_high_west/)**\n",
      "\n",
      "* **[Denning's Point](https://www.reddit.com/r/bourbon/comments/5qhgf7/dennings_point_distillery_ama_with_chief_distiller/)**\n",
      "\n",
      "* **[Chip Tate](https://docs.google.com/document/d/1eYFl8nKvaAwHP_ZVP_dgTyKe9iN0DnddN220cjMxDUU/edit)**\n",
      "\n",
      "* **[Old Rip Van Winkle](https://docs.google.com/document/d/1UThREucv_Z1EjyRNAVJ6hCjd1TNaERphwjWy2wUEmQ0/edit)**\n",
      "\n",
      "# **Stuff**\n",
      "\n",
      "* **[Guide to Wild Turkey Date Codes](https://www.reddit.com/r/bourbon/comments/5qe4zr/guide_to_wild_turkey_date_codes/)**\n",
      "\n",
      "* **[Wild Turkey Timeline](https://www.reddit.com/r/bourbon/comments/63s5fw/wild_turkey_timeline/)**\n",
      "\n",
      "* **[Whiskey Database - Who makes what](https://docs.google.com/spreadsheet/ccc?key=0AhtxpL3LiC-TdE1FTTRUV3lZQzdaUDNxSEp5XzlIQlE#gid=4)**\n",
      "\n",
      "* **[WhiskeyID - Dusty Dating Database](http://whiskeyid.com/)**\n",
      "\n",
      "* **[Buffalo Trace Single Oak Guide](https://docs.google.com/document/d/18h0q88npKsZY66pjnCFlKDXfJS4jWy7erO7n3QIqaRI/edit#heading=h.riycsdm8zk60)**\n",
      "\n",
      "* **\n",
      "* *Sipping on something else? Check out:* \n",
      "\n",
      "# **Our Spiritual Kin:**\n",
      "\n",
      "[Firewater](http://www.reddit.com/r/firewater)|[Alcohol](http://www.reddit.com/r/liquor)|[Wine](http://www.reddit.com/r/wine)|**[Pipetobacco](http://www.reddit.com/r/pipetobacco)**\n",
      ":---|:---|:---|:---\n",
      "**[Liquor](http://www.reddit.com/r/liquor)**|**[Cocktails](http://www.reddit.com/r/cocktails)**|**[Tequila](http://www.reddit.com/r/tequila)**|**[Cognac](/r/Cognac)**\n",
      "**[Gin](http://www.reddit.com/r/gin)**|**[Rum](http://www.reddit.com/r/rum)**|**[Cigars](http://www.reddit.com/r/cigars)**|**[Scotch](/r/scotch)**\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "print(subreddit.display_name)\n",
    "print(subreddit.title)\n",
    "print(subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">And now to finish up my series called \"There will be Kilchoman till the score is paid\", in which I review Kilchoman until I run out of Kilchoman.\n",
      "\n",
      "SOMEBODY GET THIS MAN MORE KILCHOMAN, STAT!\n",
      "==================\n",
      "And now to finish up my series called \"There will be Kilchoman till the score is paid\", in which I review Kilchoman until I run out of Kilchoman.\n",
      "\n",
      "It's a simple concept. I've run out.\n",
      "\n",
      "Originally I wanted to post three Kensington Wine Market Kilchoman store picks. They are located in Calgary, Alberta, Canada, before everyone starts asking about where in Kensington these exist.\n",
      "\n",
      "However sadly there was a mixup and I didn't end up with the third pick, which is ten years old. So it's not part of this review.\n",
      "\n",
      "What we do have is two different cask picks. Each roughly the same age, and almost the same cask number (oddly). We're here to see what a finish of PX has done to one, and what a year longer in ex-bourbon has done to another.\n",
      "\n",
      "Oh, and they were distilled at different points. And heck, let's be honest, we don't know where in the warehouse they were located, if one person was flipping both of them, and the other aspects that change things.\n",
      "\n",
      "Let's see how they picked Kilchoman, shall we?\n",
      "\n",
      "* * *\n",
      "\n",
      "**Kilchoman 4 2011 PX KWM Cask 446**\n",
      "\n",
      "**Price:** $143.99 CAD at Kensington Wine Market (Currently sold out)\n",
      "\n",
      "**Region:** Islay\n",
      "\n",
      "**Cask Type:** Ex-bourbon, then finished in Pedro Ximenez Sherry Casks\n",
      "\n",
      "**Cask Number:** 446/2011\n",
      "\n",
      "**Number of Bottles:** 222\n",
      "\n",
      "**Distilled:** 28th July 2011\n",
      "\n",
      "**Bottled:** 25th July 2016\n",
      "\n",
      "**Bottled for** Kensington Wine Market, Alberta\n",
      "\n",
      "**Abv:** 57.5%\n",
      "\n",
      "**Colour:** 5Y 8/8\n",
      "\n",
      "**Nose:** Raspberry, mint, balsamic vinegar, brine\n",
      "\n",
      "Interesting mixture of nice raspberry and mint on the nose. It reminds me of somewhere between a light salad dressing, and a really nice summer dessert.\n",
      "\n",
      "That said, not much pops up beyond that. It's not super complex on the nose. I want a bit more. The peat is all mint.\n",
      "\n",
      "**Taste:** Anise, papaya, coal, salami, caramel\n",
      "\n",
      "Happy with more of the peat influence on the taste. Lovely nice spice, good meatiness, and some earth/coal notes.\n",
      "\n",
      "Not to mention the PX cask has added some nice tropical vibes, and different than the typical tropical aspects. In other words, papaya is pretty awesome and I'm happy it's here.\n",
      "\n",
      "**Finish:** Pepper, basil, orange zest, lemon-lime soda, coal\n",
      "\n",
      "Finish is pretty young. I think this was what they were aiming to hide it with the PX cask. It's pretty rough.\n",
      "\n",
      "**Conclusion:** An interesting nose, and while I was hoping for more on it, I can see the appeal. The taste has what I feel should have been throughout the whisky. And the finish needed more work.\n",
      "\n",
      "So it's nice, but not great. You need to dig through it. And ignore the finish. And that the nose is simple but nice.\n",
      "\n",
      "**77/100**\n",
      "\n",
      "* * *\n",
      "\n",
      "**Kilchoman 5 2010 KWM Cask 440**\n",
      "\n",
      "**Price:** $139.99 CAD at Kensington Wine Market (I think this is sold out)\n",
      "\n",
      "**Region:** Islay\n",
      "\n",
      "**Cask Type:** Ex-bourbon barrel\n",
      "\n",
      "**Cask Number:** 440/2010\n",
      "\n",
      "**Number of Bottles:** 221\n",
      "\n",
      "**Distilled:** August 26th, 2010\n",
      "\n",
      "**Bottled:** July 10th, 2015\n",
      "\n",
      "**Bottled for** Kensington Wine Market, Alberta\n",
      "\n",
      "**Abv:** 60.4%\n",
      "\n",
      "**Colour:** 7.5Y 9/6\n",
      "\n",
      "**Nose:** Straw/manure, BBQ chicken, cocoa, sweet cornbread\n",
      "\n",
      "Now we're cooking. Initial barnyard notes that just rock me right to my childhood... visiting the cousins who lived on a farm. \n",
      "\n",
      "Eventually, there's wonderful Umami/BBQ notes, good cocoa, and water brings out some sweet, corn notes.\n",
      "\n",
      "**Taste:** Tarragon, vanilla, mango, coconut macaroons\n",
      "\n",
      "Initial note threw me off a bit. I'm not used to the type of herbal on it. Given time/water, that moves to the side, with lots of vanilla, mango, and coconut popping up.\n",
      "\n",
      "**Finish:** Wheat, salted caramel, sunflower seeds, apricot, candied ginger\n",
      "\n",
      "Cereal... what the heck? It pops with the sweetness from the taste, has some cereal and seed notes, and then a finish with fruit and ginger.\n",
      "\n",
      "**Conclusion:** Very unique. Goes in a different direction than other Kilchomans I've had. It's what you want from a single cask. It's doing something interesting.\n",
      "\n",
      "Overall there are some things that don't really work. The big herbal note on the taste was jarring. The finish had a mixture of seeds and cereal that wasn't off, but was kinda like those seed crackers you get at Halloween. Or that I used to get, cause I'm old.\n",
      "\n",
      "This is the bottle to buy.\n",
      "\n",
      "**83/100**\n",
      "\n",
      "*Scotch review #904-905, Islay review #237-238, Whisky Network review #1442-1443*\n",
      "\n",
      "*Other Kilchoman reviews:*\n",
      "\n",
      "* [Kilchoman 100% Islay - 3rd Edition](http://www.reddit.com/r/Scotch/comments/2ndepm/kilchoman_quintuple_review_100_islay_3rd_edition/)\n",
      "\n",
      "* [Kilchoman 4 2010 - Single Quarter Cask Release (cask 582/2010)](https://www.reddit.com/r/Scotch/comments/8p0g57/kilchoman_4_2010_single_quarter_cask_release_cask/)\n",
      "\n",
      "* [Kilchoman 4 2011 Madeira Cask](https://www.reddit.com/r/Scotch/comments/8p9q98/kilchoman_4_2011_madeira_cask_review/)\n",
      "\n",
      "* [Kilchoman 4 2012 Red Wine Cask](https://www.reddit.com/r/Scotch/comments/8qir9g/kilchoman_4_2012_red_wine_cask_review/)\n",
      "\n",
      "* [Kilchoman 5 2009 Original Cask Strength](https://www.reddit.com/r/Scotch/comments/8qrz3a/kilchoman_5_2009_original_cask_strength_review/)\n",
      "\n",
      "* [Kilchoman 5 2009 Single Cask Sherry bottled for the Nectar Belgium](https://www.reddit.com/r/Scotch/comments/8pjjqf/kilchoman_6_2009_single_cask_sherry_bottled_for/)\n",
      "\n",
      "* [Kilchoman 7 2008](https://www.reddit.com/r/Scotch/comments/8q96fw/kilchoman_7_2008_review/)\n",
      "\n",
      "* [Kilchoman Batch 1 (That Boutique-y Whisky Company)](http://www.reddit.com/r/Scotch/comments/2ndepm/kilchoman_quintuple_review_100_islay_3rd_edition/)\n",
      "\n",
      "* [Kilchoman Club Release 5 2016: 10](https://www.reddit.com/r/Scotch/comments/5op0ef/jj_xmas_mystery_samples_10_16_review/)\n",
      "\n",
      "* [Kilchoman Coull Point](https://www.reddit.com/r/Scotch/comments/8oh5k3/kilchoman_coull_point_review/)\n",
      "\n",
      "* [Kilchoman Loch Gorm 2013](http://www.reddit.com/r/Scotch/comments/2ndepm/kilchoman_quintuple_review_100_islay_3rd_edition/)\n",
      "\n",
      "* [Kilchoman Machir Bay](http://www.reddit.com/r/Scotch/comments/1696x2/kilchoman_machir_bay_reviewlife_lessonsmagic/)\n",
      "\n",
      "* [Kilchoman Port Cask Matured](http://www.reddit.com/r/Scotch/comments/2ndepm/kilchoman_quintuple_review_100_islay_3rd_edition/)\n",
      "\n",
      "* [Kilchoman Sanaig](https://www.reddit.com/r/Scotch/comments/8oqa31/kilchoman_sanaig_review/)\n",
      "\n",
      "* [Kilchoman Single Bourbon Cask 5](http://www.reddit.com/r/Scotch/comments/1m10vh/kilchoman_single_bourbon_cask_5_year_old_review/)\n",
      "\n",
      "* [Kilchoman Single Bourbon Cask 5 (Re-Review)](http://www.reddit.com/r/Scotch/comments/2ndepm/kilchoman_quintuple_review_100_islay_3rd_edition/)\n",
      "\n",
      "[Link to my website with all my reviews](http://tomoderawhisky.wordpress.com)\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "for top_level_comment in submission.comments:\n",
    "    print(top_level_comment.body)\n",
    "    print(\"==================\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
